# -*- coding: utf-8 -*-
"""Traffic data

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BJ2y20mzLt04t-BD41-fNt-3MhGI03xu
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

"""## ***Data cleaning ***"""

df=pd.read_csv('Car.csv')

df

df.head()

df.tail()

df.info()

df.columns

df.index

df.isnull()

df.isna().sum()

data=df.head(6)
data

"""# Data visualization

"""

sns.scatterplot(data,x='Overtaking Cases',y='State/UT/City')

sns.scatterplot(data,x= 'Overtaking Cases',y='Overtaking Injured' ,hue='State/UT/City')

# distplot for purchase
plt.style.use('fivethirtyeight')
plt.figure(figsize=(10,8))
sns.distplot(df['Overtaking Cases'])

# bivariate analysis
occupation_plot = data.pivot_table(index='State/UT/City', values='Overtaking Cases', aggfunc=np.mean)
occupation_plot.plot(kind='bar', figsize=(13, 7))
plt.xlabel('State/UT/City')
plt.ylabel("Overtaking Cases")
plt.title("State/UT/City Wise Overtaking Cases")
plt.xticks(rotation=40)
plt.show()

# bivariate analysis

occupation_plot = data.pivot_table(index='State/UT/City', values='Overtaking Injured', aggfunc=np.mean)
occupation_plot.plot(kind='bar', figsize=(13, 7))
plt.xlabel('State/UT/City')
plt.ylabel("Overtaking Injured")
plt.title("State/UT/City Wise Overtaking Cases")
plt.xticks(rotation=40)
plt.show()

data

data1=df.loc[10:15]
data1

occupation_plot = data1.pivot_table(index='State/UT/City', values='Overtaking Injured', aggfunc=np.mean)
occupation_plot.plot(kind='bar', figsize=(13, 7))
plt.xlabel('State/UT/City')
plt.ylabel("Overtaking Injured")
plt.title("State/UT/City Wise Overtaking Cases")
plt.xticks(rotation=40)
plt.show()

import matplotlib.pyplot as plt

x=data1['State/UT/City']
y=data1['Overtaking Cases']

# Create a line plot
plt.figure(figsize=(8, 6))
plt.plot(x, y, label='Data Points', color='blue', marker='o', linestyle='-')

# Add labels and a title
plt.xlabel('X-axis Label')
plt.ylabel('Y-axis Label')
plt.title('Line Plot Example')
plt.xticks(rotation=40)

# Add a legend
plt.legend()

# Show the line plot
plt.grid(True)
plt.show()



df1=df.drop(columns=['Total Road Accidents Cases'])

x=df1['Overtaking Cases']
y=df1['Overspeeding Injured']

plt.scatter(x,y)

x=data1['Overspeeding Cases']
y=data1['Overtaking Injured']

plt.scatter(x,y)

df

import numpy as np
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler, KBinsDiscretizer
from sklearn.compose import ColumnTransformer



x = ["Overtaking Cases"]
y = ["Overtaking Injured"]

preprocessor = ColumnTransformer(
    transformers=[
        ("scaler", StandardScaler(), x),
        ("kbin", KBinsDiscretizer(encode="ordinal"), y)
    ],
    verbose_feature_names_out=False
)

X_out = preprocessor.fit_transform(data)

# Create a DataFrame with the transformed data
X_out_df = pd.DataFrame(X_out, columns=x + y)
X_out_df.sample(n=5, random_state=0)

from sklearn.datasets import load_diabetes
from sklearn.experimental import enable_hist_gradient_boosting
from sklearn.ensemble import HistGradientBoostingRegressor

X, y = load_diabetes(return_X_y=True, as_frame=True)

hist_no_interact = HistGradientBoostingRegressor(random_state=0)
hist_no_interact.fit(X, y)

import matplotlib.pyplot as plt
from sklearn.metrics import PredictionErrorDisplay
from sklearn.ensemble import HistGradientBoostingRegressor
from sklearn.datasets import load_diabetes

X, y = load_diabetes(return_X_y=True, as_frame=True)
hist_no_interact = HistGradientBoostingRegressor(random_state=0)
hist_no_interact.fit(X, y)

fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))

# Create PredictionErrorDisplay for "actual_vs_predicted" and "residual_vs_predicted"
ped_actual_vs_pred = PredictionErrorDisplay.from_estimator(hist_no_interact, X, y, kind="actual_vs_predicted")
ped_residual_vs_pred = PredictionErrorDisplay.from_estimator(hist_no_interact, X, y, kind="residual_vs_predicted")

# Display the plots on the specified subplots
ped_actual_vs_pred.plot(ax=axs[0])
ped_residual_vs_pred.plot(ax=axs[1])

plt.show()

from sklearn.model_selection import LearningCurveDisplay

_ = LearningCurveDisplay.from_estimator(
    hist_no_interact, X, y, cv=5, n_jobs=2, train_sizes=np.linspace(0.1, 1, 5)
)

from sklearn.datasets import fetch_openml

# Fetch the Titanic dataset
titanic = fetch_openml("titanic", version=1, as_frame=True, parser="pandas")

# Extract the features (X) and target (y)
X = titanic.data
y = titanic.target

# Select columns with data types "number" and "category" and drop the "body" column
X = X.select_dtypes(include=["number", "category"]).drop(columns=["body"])

import numpy as np
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.inspection import PartialDependenceDisplay
from sklearn.ensemble import HistGradientBoostingRegressor

n_samples = 500
rng = np.random.RandomState(0)
X = rng.randn(n_samples, 2)
noise = rng.normal(loc=0.0, scale=0.01, size=n_samples)
y = 5 * X[:, 0] + np.sin(10 * np.pi * X[:, 0]) - noise

gbdt_no_cst = HistGradientBoostingRegressor().fit(X, y)
gbdt_cst = HistGradientBoostingRegressor(monotonic_cst=[1, 0]).fit(X, y)

disp = PartialDependenceDisplay.from_estimator(
    gbdt_no_cst,
    X,
    features=[0],
    feature_names=["feature 0"],
    line_kw={"linewidth": 4, "label": "unconstrained", "color": "tab:blue"}
)

PartialDependenceDisplay.from_estimator(
    gbdt_cst,
    X,
    features=[0],
    line_kw={"linewidth": 4, "label": "constrained", "color": "tab:orange"},
    ax=disp.axes_
)

disp.axes_[0, 0].plot(
    X[:, 0], y, "o", alpha=0.5, zorder=-1, label="samples", color="tab:green"
)
disp.axes_[0, 0].set_ylim(-3, 3)
disp.axes_[0, 0].set_xlim(-1, 1)
plt.legend()
plt.show()

df

y=df["Total Road Accidents Cases"]
y

x = df.drop(["Total Road Accidents Cases", "State/UT/City"], axis=1)

x

from sklearn.model_selection import train_test_split

x_train, x_test ,y_train,y_test = train_test_split(x,y,test_size=0.2 ,random_state=100)

x_train.dropna(axis=0, inplace=True)
y_train = y_train[x_train.index]

x_train

x_test

from sklearn.impute import SimpleImputer

# Create a SimpleImputer with the strategy you prefer (e.g., 'mean', 'median', 'most_frequent')
imputer = SimpleImputer(strategy='mean')

# Fit and transform the imputer on your training data for x_train
x_train_imputed = imputer.fit_transform(x_train)

# Transform the imputer on your test data for x_test (if needed)
x_test_imputed = imputer.transform(x_test)

y_train

"""## Model bilding

## Linear rigration
"""

from sklearn.linear_model import LinearRegression
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression

lr = LinearRegression()
lr.fit(x_train,y_train)

"""Applying the model to make a prediction"""

y_lr_train_pred = lr.predict(x_train)
y_lr_test_pred= lr.predict(x_test)

y_lr_train_pred

y_lr_test_pred

"""**Evaluate**"""

from sklearn.metrics import mean_squared_error ,r2_score

lr_train_mse = mean_squared_error(y_train ,y_lr_train_pred)
lr_train_r2 =r2_score(y_train ,y_lr_train_pred)\

lr_test_mse =mean_squared_error(y_test,y_lr_test_pred)
lr_test_r2 =r2_score(y_test,y_lr_test_pred)

print('LR MSE (Train),' ,lr_train_mse)
print('LR MSE (Train),' ,lr_train_r2)
print('LR MSE (Test),' ,lr_test_mse)
print('LR MSE (Test),' ,lr_test_r2)

# Import necessary libraries
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Assuming df1 is the DataFrame you want to use for linear regression
# Drop any remaining NaN values
df1 = df1.dropna()

# Select features and target variable
X = df1[['Overtaking Cases']]
y = df1['Overspeeding Injured']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a Linear Regression model
model = LinearRegression()

# Train the model
model.fit(X_train, y_train)

# Make predictions on the training set
y_train_pred = model.predict(X_train)

# Make predictions on the testing set
y_test_pred = model.predict(X_test)

# Evaluate the model
train_mse = mean_squared_error(y_train, y_train_pred)
train_r2 = r2_score(y_train, y_train_pred)

test_mse = mean_squared_error(y_test, y_test_pred)
test_r2 = r2_score(y_test, y_test_pred)

# Display the results
print("Training MSE:", train_mse)
print("Training R^2:", train_r2)
print("Testing MSE:", test_mse)
print("Testing R^2:", test_r2)

# Plot the regression line on the scatter plot
plt.scatter(X, y, label='Actual data')
plt.plot(X, model.predict(X), color='red', label='Regression Line')
plt.xlabel('Overtaking Cases')
plt.ylabel('Overspeeding Injured')
plt.title('Linear Regression')
plt.legend()
plt.show()

